{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis 2: The number of engagements (i.e., likes, replies, retweets, and quote retweets) on tweets spreading misinformation/disinformation also dropped over time after the release of Rappler's Fact Checking Article last April 25, 2019."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the hypothesis and the structure of the dataset, the appropriate statistical test for **Hypothesis 2** is an **independent samples t-test**. This test is suitable for comparing the means of the engagement metric (i.e., number of engagements) between two independent groups: tweets before April 25, 2019, and tweets after that date.\n",
    "\n",
    "Here's a more detailed explanation of why an independent samples t-test is appropriate for Hypothesis 2:\n",
    "\n",
    "- **Independent Groups**: The hypothesis aims to compare the number of engagements (i.e., likes, replies, retweets, and quote retweets) on tweets before and after the release of Rappler's Fact Checking Article on April 25, 2019. The tweets before and after this date represent two independent groups. The engagements in one group are not related to or dependent on the engagements in the other group. Therefore, an independent samples t-test is suitable for comparing the means between these two independent groups.\n",
    "\n",
    "- **Continuous Variables**: The engagement metrics (likes, replies, retweets, and quote retweets) are continuous variables that can be treated as numerical quantities. An independent samples t-test can effectively compare the means of these continuous variables between the two groups.\n",
    "\n",
    "- **Research Question**: The hypothesis states that the number of engagements on tweets spreading misinformation/disinformation dropped over time after the release of Rappler's Fact Checking Article. The focus is on the difference in means between engagements on tweets before and after April 25, 2019. An independent samples t-test is well-suited for addressing this research question by comparing the means of the engagement metrics in the two groups.\n",
    "\n",
    "By employing an independent samples t-test, you can effectively analyze whether there is a significant difference in the means of engagements (likes, replies, retweets, and quote retweets) between tweets before and after the release of Rappler's Fact Checking Article on April 25, 2019, thus addressing **Hypothesis 2** in your analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 0: Repeated measures ANOVA assumptions check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import data to pandas dataframe\n",
    "df = pd.read_csv('../../Data Exploration/cleaned_dataset.csv')\n",
    "\n",
    "df['Engagements'] = df['Quote Tweets'] + df['Replies'] + df['Likes'] + df['Retweets']\n",
    "\n",
    "df['Date posted'] = pd.to_datetime(df['Date posted'])\n",
    "\n",
    "# before: engagement metrics before April 25, 2019\n",
    "before = df[df['Date posted'] < '2019-04-25']['Engagements']\n",
    "\n",
    "# after: engagement metrics after April 25, 2019\n",
    "after = df[df['Date posted'] >= '2019-04-25']['Engagements']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 1582.5\n",
      "P-value: 0.34849080628465023\n",
      "The null hypothesis of independence is not rejected. The groups are independent.\n"
     ]
    }
   ],
   "source": [
    "# Perform the independence test\n",
    "statistic, p_value = stats.mannwhitneyu(before, after, alternative='two-sided')\n",
    "\n",
    "# Set significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the results\n",
    "print('Statistic:', statistic)\n",
    "print('P-value:', p_value)\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The null hypothesis of independence is rejected. The groups are dependent.\")\n",
    "else:\n",
    "    print(\"The null hypothesis of independence is not rejected. The groups are independent.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic before: 0.5465950965881348\n",
      "P-value before: 1.2118325010135322e-08\n",
      "Statistic after: 0.45283329486846924\n",
      "P-value after: 9.835117512661089e-19\n",
      "The engagement metrics in at least one of the groups do not approximate a normal distribution.\n"
     ]
    }
   ],
   "source": [
    "# Perform the Shapiro-Wilk test for normality\n",
    "statistic_before, p_value_before = stats.shapiro(before)\n",
    "statistic_after, p_value_after = stats.shapiro(after)\n",
    "\n",
    "# Print the results\n",
    "print('Statistic before:', statistic_before)\n",
    "print('P-value before:', p_value_before)\n",
    "\n",
    "print('Statistic after:', statistic_after)\n",
    "print('P-value after:', p_value_after)\n",
    "\n",
    "# Set significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-values are greater than the significance level\n",
    "if p_value_before > alpha and p_value_after > alpha:\n",
    "    print(\"The engagement metrics in both groups approximate a normal distribution.\")\n",
    "else:\n",
    "    print(\"The engagement metrics in at least one of the groups do not approximate a normal distribution.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Homogenity of Variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variances of engagement metrics in the two groups are equal.\n",
      "The standard deviation of engagement metrics in the 'before' group is larger.\n"
     ]
    }
   ],
   "source": [
    "# Perform Levene's test for homogeneity of variance\n",
    "statistic, p_value = stats.levene(before, after)\n",
    "\n",
    "# Calculate the standard deviations of the two groups\n",
    "std_dev_before = np.std(before)\n",
    "std_dev_after = np.std(after)\n",
    "\n",
    "# Set significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-value is greater than the significance level\n",
    "if p_value > alpha:\n",
    "    print(\"The variances of engagement metrics in the two groups are equal.\")\n",
    "else:\n",
    "    print(\"The variances of engagement metrics in the two groups are not equal.\")\n",
    "\n",
    "# Compare the standard deviations\n",
    "if std_dev_before > std_dev_after:\n",
    "    print(\"The standard deviation of engagement metrics in the 'before' group is larger.\")\n",
    "elif std_dev_before < std_dev_after:\n",
    "    print(\"The standard deviation of engagement metrics in the 'after' group is larger.\")\n",
    "else:\n",
    "    print(\"The standard deviations of engagement metrics in the two groups are equal.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Interval or Ratio Data\n",
    "\n",
    "- The assumption that the engagement metrics should be measured on an interval or ratio scale is typically satisfied since engagement metrics like likes, replies, retweets, and quote retweets are indeed continuous variables. Therefore, no specific statistical test is required to assess this assumption.\n",
    "- However, it is always good practice to ensure that the engagement metrics in your dataset are indeed numerical and continuous. You can perform some basic checks to confirm this. Here's an example code snippet that demonstrates how to check if the engagement metrics are numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likes is a numeric column.\n",
      "Replies is a numeric column.\n",
      "Retweets is a numeric column.\n",
      "Quote Tweets is a numeric column.\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of the engagement metric columns\n",
    "engagement_metrics = ['Likes', 'Replies', 'Retweets', 'Quote Tweets']\n",
    "\n",
    "for metric in engagement_metrics:\n",
    "    if pd.api.types.is_numeric_dtype(df[metric]):\n",
    "        print(f\"{metric} is a numeric column.\")\n",
    "    else:\n",
    "        print(f\"{metric} is not a numeric column.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Selection of a non-parametric test**\n",
    "\n",
    "While the assumptions of independence, homogeneity of variance, and interval or ratio data are satisfied in this analysis, the assumption of normality is not met for the engagement metrics in both groups. Therefore, the independent samples t-test, which assumes normality, is not appropriate for comparing the engagement metrics between the two groups before and after April 25, 2019. Let's try looking into Non-parametric tests, in particular let's look into the Mann-Whitney U test or permutation test are more suitable alternatives. These tests do not rely on the assumption of normality and can be used to assess the difference between two independent groups based on their ranks or by permutation of the data.\n",
    "\n",
    "Here's an in-depth explanation of why the Mann-Whitney U test or permutation test are more suitable alternatives when the assumption of normality is not satisfied:\n",
    "\n",
    "1. **Mann-Whitney U test**: The Mann-Whitney U test, also known as the Wilcoxon rank-sum test, is a non-parametric test used to compare two independent groups. It does not rely on the assumption of normality and instead compares the ranks of the observations between the two groups. Here's why it is a suitable alternative:\n",
    "\n",
    "   - Robust to non-normality: The Mann-Whitney U test does not assume a specific distribution for the data, making it robust to violations of the normality assumption. It focuses on the ordering of the observations rather than their exact values.\n",
    "   \n",
    "   - Based on medians: The Mann-Whitney U test compares the medians of the two groups. If the distributions of the engagement metrics in the two groups differ, it is likely to result in a significant difference in the medians.\n",
    "   \n",
    "   - Assumptions: The Mann-Whitney U test assumes that the observations in each group are independent and that the engagement metrics are measured on an ordinal scale or higher.\n",
    "   \n",
    "   - Interpretation: The test provides a p-value that indicates the likelihood of obtaining the observed difference in medians (or more extreme) by chance alone. If the p-value is below a pre-defined significance level, it suggests a significant difference between the two groups.\n",
    "\n",
    "2. **Permutation test**: A permutation test, also known as a randomization test or exact test, is a non-parametric resampling-based test that provides an alternative way to assess the statistical significance of the difference between two groups. Here's why it is a suitable alternative:\n",
    "\n",
    "   - No assumptions about the data distribution: The permutation test does not rely on any assumptions about the data distribution, including normality. It works by randomly permuting the observations between the two groups, recalculating the test statistic, and repeating this process many times to obtain the empirical null distribution.\n",
    "   \n",
    "   - Flexible and adaptable: The permutation test can be applied to a wide range of data types and study designs, making it a versatile tool for hypothesis testing. It allows for customized test statistics based on your research question and provides a p-value based on the empirical null distribution.\n",
    "   \n",
    "   - Robustness: The permutation test is robust against violations of assumptions like normality and homogeneity of variance. It provides reliable results even when the data does not meet the assumptions of traditional parametric tests.\n",
    "   \n",
    "   - Validity: The permutation test provides exact p-values and maintains the desired type I error rate, meaning that the reported p-value is the exact probability of observing a test statistic as extreme as or more extreme than the observed statistic under the null hypothesis.\n",
    "   \n",
    "   - Interpretation: The p-value obtained from the permutation test represents the likelihood of obtaining the observed test statistic (or a more extreme value) under the null hypothesis. If the p-value is below a pre-defined significance level, it suggests a significant difference between the two groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Perform the Mann-Whitney U Test and interpret the results**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test statistic: 1582.5\n",
      "p-value: 0.34849080628465023\n",
      "There is no significant difference between the two groups.\n"
     ]
    }
   ],
   "source": [
    "# Perform the Mann-Whitney U test for the engagements of the 2 groups\n",
    "statistic, p_value = stats.mannwhitneyu(before, after, alternative='two-sided')\n",
    "\n",
    "# Set significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Print the test result\n",
    "print(f\"Mann-Whitney U test statistic: {statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the two groups.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Perform the Permutation test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed test statistic: 0.4142614601018675\n",
      "p-value: 0.703\n",
      "There is no significant difference between the two groups.\n"
     ]
    }
   ],
   "source": [
    "# Compute the observed test statistic (e.g., difference in means, difference in medians)\n",
    "observed_statistic = np.mean(before) - np.mean(after)\n",
    "\n",
    "# Perform the permutation test\n",
    "num_permutations = 1000  # Number of permutations\n",
    "permutation_stats = []\n",
    "\n",
    "for _ in range(num_permutations):\n",
    "    # Shuffle the data between the two groups\n",
    "    combined_data = np.concatenate((before, after))\n",
    "    np.random.shuffle(combined_data)\n",
    "    \n",
    "    # Compute the test statistic for the permuted data\n",
    "    permuted_statistic = np.mean(combined_data[:len(before)]) - np.mean(combined_data[len(before):])\n",
    "    permutation_stats.append(permuted_statistic)\n",
    "\n",
    "# Compute the p-value as the proportion of permutation statistics greater than or equal to the observed statistic\n",
    "p_value = (np.abs(permutation_stats) >= np.abs(observed_statistic)).mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Observed test statistic: {observed_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Set significance level (alpha)\n",
    "alpha = 0.05\n",
    "\n",
    "# Check if the p-value is less than the significance level\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference between the two groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference between the two groups.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSION**\n",
    "\n",
    "Based on the results of both the **Mann-Whitney U test** and the **permutation test**, which indicate that there is **no significant difference** between the two groups, we **fail to reject the null hypothesis**.\n",
    "\n",
    "Therefore, we **do not have sufficient evidence** to conclude that the number of engagements (likes, replies, retweets, and quote retweets) on tweets spreading misinformation/disinformation dropped over time after the release of Rappler's Fact Checking Article last April 25, 2019. The data does not support the hypothesis that the engagement metrics significantly decreased following the article's release.\n",
    "\n",
    "It's important to note that failing to find a significant difference does not necessarily mean that there is no effect. It could be possible that the effect is small or that other factors are influencing the engagement metrics. However, based on the available data and the statistical tests performed, we cannot confidently conclude that there was a significant drop in engagements after the article's release."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
